---
---

@string{aps = {American Physical Society,}}
@inproceedings{mamta-etal-2024-biaswipe,
    title = "{B}ias{W}ipe: Mitigating Unintended Bias in Text Classifiers through Model Interpretability",
    author = "Mamta, Mamta  and
      Chigrupaatii, Rishikant  and
      Ekbal, Asif",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-main.1172/",
    doi = "10.18653/v1/2024.emnlp-main.1172",
    pages = "21059--21070",
    abstract = "Toxic content detection plays a vital role in addressing the misuse of social media platforms to harm people or groups due to their race, gender or ethnicity. However, due to the nature of the datasets, systems develop an unintended bias due to the over-generalization of the model to the training data. This compromises the fairness of the systems, which can impact certain groups due to their race, gender, etc.Existing methods mitigate bias using data augmentation, adversarial learning, etc., which require re-training and adding extra parameters to the model.In this work, we present a robust and generalizable technique \textit{BiasWipe} to mitigate unintended bias in language models. \textit{BiasWipe} utilizes model interpretability using Shapley values, which achieve fairness by pruning the neuron weights responsible for unintended bias. It first identifies the neuron weights responsible for unintended bias and then achieves fairness by pruning them without loss of original performance. It does not require re-training or adding extra parameters to the model. To show the effectiveness of our proposed technique for bias unlearning, we perform extensive experiments for Toxic content detection for BERT, RoBERTa, and GPT models. ."
    selected={true}
}
@article{---,
  title={Atmosphere kamaal ka tha (was wonderful): A Multilingual Joint Learning Framework for Aspect Category Detection and Sentiment Classification},
  author={Mamta and Ekbal, Asif},
  journal={IEEE Transactions on Computational Social Systems},
  year={2024},
  selected={true}
}

@article{ahmad2023elevating,
  title={Elevating Code-mixed Text Handling through Auditory Information of Words},
  author={Ahmad, Zishan and Ekbal, Asif and others},
  journal={Conference on Empirical Methods in Natural Language Processing},
  year={2023},
  selected={true}
}

@article{mamta2023transformer,
  title={Transformer based multilingual joint learning framework for code-mixed and english sentiment analysis},
  author={Mamta and Ekbal, Asif},
  journal={Journal of Intelligent Information Systems},
  pages={1--23},
  year={2023},
  publisher={Springer}
}

@inproceedings{mamta2023service,
  title={Service is good, very good or excellent? towards aspect based sentiment intensity analysis},
  author={Mamta and Ekbal, Asif},
  booktitle={European Conference on Information Retrieval},
  pages={685--700},
  year={2023},
  organization={Springer},
  selected={true}
}

@inproceedings{ekbal2022adversarial,
  title={Adversarial sample generation for aspect based sentiment classification},
  author={Ekbal, Asif and others},
  booktitle={Findings of the Association for Computational Linguistics: AACL-IJCNLP 2022},
  pages={478--492},
  year={2022},
  selected={true}
}

@article{mamta2022exploring,
  title={Exploring multi-lingual, multi-task, and adversarial learning for low-resource sentiment analysis},
  author={Mamta and Ekbal, Asif and Bhattacharyya, Pushpak},
  journal={Transactions on Asian and Low-Resource Language Information Processing},
  volume={21},
  number={5},
  pages={1--19},
  year={2022},
  publisher={ACM New York, NY}
}

@inproceedings{ekbal2020multi,
  title={Multi-domain tweet corpora for sentiment analysis: resource creation and evaluation},
  author={Ekbal, Asif and Bhattacharyya, Pushpak and Srivastava, Shikha and Kumar, Alka and Saha, Tista and others},
  booktitle={Proceedings of the Twelfth Language Resources and Evaluation Conference},
  pages={5046--5054},
  year={2020}
}

@inproceedings{ekbal2022hindimd,
  title={HindiMD: A multi-domain corpora for low-resource sentiment analysis},
  author={Ekbal, Asif and Bhattacharyya, Pushpak and Saha, Tista and Kumar, Alka and Srivastava, Shikha and others},
  booktitle={Proceedings of the Thirteenth Language Resources and Evaluation Conference},
  pages={7061--7070},
  year={2022}
}

@inproceedings{behera2020only,
  title={Only text? only image? or both? Predicting sentiment of internet memes},
  author={Behera, Pranati and Ekbal, Asif and others},
  booktitle={Proceedings of the 17th International Conference on Natural Language Processing (ICON)},
  pages={444--452},
  year={2020}
}
